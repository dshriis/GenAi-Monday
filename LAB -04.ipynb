{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iPcmAMc_AhCH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dataset\n",
        "\n",
        "\n",
        "text = \"\"\"\n",
        "artificial intelligence is transforming modern society.\n",
        "it is used in healthcare finance education and transportation.\n",
        "machine learning allows systems to improve automatically with experience.\n",
        "data plays a critical role in training intelligent systems.\n",
        "large datasets help models learn complex patterns.\n",
        "deep learning uses multi layer neural networks.\n",
        "neural networks are inspired by biological neurons.\n",
        "each neuron processes input and produces an output.\n",
        "training a neural network requires optimization techniques.\n",
        "gradient descent minimizes the loss function.\n",
        "\n",
        "natural language processing helps computers understand human language.\n",
        "text generation is a key task in nlp.\n",
        "language models predict the next word or character.\n",
        "recurrent neural networks handle sequential data.\n",
        "lstm and gru models address long term dependency problems.\n",
        "however rnn based models are slow for long sequences.\n",
        "\n",
        "transformer models changed the field of nlp.\n",
        "they rely on self attention mechanisms.\n",
        "attention allows the model to focus on relevant context.\n",
        "transformers process data in parallel.\n",
        "this makes training faster and more efficient.\n",
        "modern language models are based on transformers.\n",
        "\n",
        "education is being improved using artificial intelligence.\n",
        "intelligent tutoring systems personalize learning.\n",
        "automated grading saves time for teachers.\n",
        "online education platforms use recommendation systems.\n",
        "technology enhances the quality of learning experiences.\n",
        "\n",
        "ethical considerations are important in artificial intelligence.\n",
        "fairness transparency and accountability must be ensured.\n",
        "ai systems should be designed responsibly.\n",
        "data privacy and security are major concerns.\n",
        "researchers continue to improve ai safety.\n",
        "\n",
        "text generation models can create stories poems and articles.\n",
        "they are used in chatbots virtual assistants and content creation.\n",
        "generated text should be meaningful and coherent.\n",
        "evaluation of text generation is challenging.\n",
        "human judgement is often required.\n",
        "\n",
        "continuous learning is essential in the field of ai.\n",
        "research and innovation drive technological progress.\n",
        "students should build strong foundations in mathematics.\n",
        "programming skills are important for ai engineers.\n",
        "practical experimentation enhances understanding.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "qm8zSp5gELS8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "oEmRSjfEEhKY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "ivbRITgyEvN8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLa3OvERFHEs",
        "outputId": "989536d8-3db6-477b-862a-23c3cd726437"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentence in text.split('\\n'):\n",
        "    #print(sentence)\n",
        "    #print(tokenizer.texts_to_sequences([sentence])[0])\n",
        "    tokenizer_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1,len(tokenizer_sentence)):\n",
        "        input_sequences.append(tokenizer_sentence[:i+1])"
      ],
      "metadata": {
        "id": "3BFDthPDFSCF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print list\n",
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4mfhS6JFg-R",
        "outputId": "f2b1137c-db8e-46f8-9f86-6b52211413ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[15, 16],\n",
              " [15, 16, 3],\n",
              " [15, 16, 3, 42],\n",
              " [15, 16, 3, 42, 27],\n",
              " [15, 16, 3, 42, 27, 43],\n",
              " [44, 3],\n",
              " [44, 3, 28],\n",
              " [44, 3, 28, 2],\n",
              " [44, 3, 28, 2, 45],\n",
              " [44, 3, 28, 2, 45, 46],\n",
              " [44, 3, 28, 2, 45, 46, 17],\n",
              " [44, 3, 28, 2, 45, 46, 17, 1],\n",
              " [44, 3, 28, 2, 45, 46, 17, 1, 47],\n",
              " [48, 7],\n",
              " [48, 7, 29],\n",
              " [48, 7, 29, 8],\n",
              " [48, 7, 29, 8, 18],\n",
              " [48, 7, 29, 8, 18, 30],\n",
              " [48, 7, 29, 8, 18, 30, 49],\n",
              " [48, 7, 29, 8, 18, 30, 49, 50],\n",
              " [48, 7, 29, 8, 18, 30, 49, 50, 51],\n",
              " [9, 52],\n",
              " [9, 52, 19],\n",
              " [9, 52, 19, 53],\n",
              " [9, 52, 19, 53, 54],\n",
              " [9, 52, 19, 53, 54, 2],\n",
              " [9, 52, 19, 53, 54, 2, 20],\n",
              " [9, 52, 19, 53, 54, 2, 20, 31],\n",
              " [9, 52, 19, 53, 54, 2, 20, 31, 8],\n",
              " [55, 56],\n",
              " [55, 56, 57],\n",
              " [55, 56, 57, 4],\n",
              " [55, 56, 57, 4, 58],\n",
              " [55, 56, 57, 4, 58, 59],\n",
              " [55, 56, 57, 4, 58, 59, 60],\n",
              " [61, 7],\n",
              " [61, 7, 62],\n",
              " [61, 7, 62, 63],\n",
              " [61, 7, 62, 63, 64],\n",
              " [61, 7, 62, 63, 64, 10],\n",
              " [61, 7, 62, 63, 64, 10, 21],\n",
              " [10, 21],\n",
              " [10, 21, 5],\n",
              " [10, 21, 5, 65],\n",
              " [10, 21, 5, 65, 66],\n",
              " [10, 21, 5, 65, 66, 67],\n",
              " [10, 21, 5, 65, 66, 67, 68],\n",
              " [69, 70],\n",
              " [69, 70, 71],\n",
              " [69, 70, 71, 72],\n",
              " [69, 70, 71, 72, 1],\n",
              " [69, 70, 71, 72, 1, 73],\n",
              " [69, 70, 71, 72, 1, 73, 74],\n",
              " [69, 70, 71, 72, 1, 73, 74, 75],\n",
              " [20, 19],\n",
              " [20, 19, 10],\n",
              " [20, 19, 10, 76],\n",
              " [20, 19, 10, 76, 77],\n",
              " [20, 19, 10, 76, 77, 78],\n",
              " [20, 19, 10, 76, 77, 78, 79],\n",
              " [80, 81],\n",
              " [80, 81, 82],\n",
              " [80, 81, 82, 6],\n",
              " [80, 81, 82, 6, 83],\n",
              " [80, 81, 82, 6, 83, 84],\n",
              " [85, 11],\n",
              " [85, 11, 86],\n",
              " [85, 11, 86, 87],\n",
              " [85, 11, 86, 87, 88],\n",
              " [85, 11, 86, 87, 88, 89],\n",
              " [85, 11, 86, 87, 88, 89, 32],\n",
              " [85, 11, 86, 87, 88, 89, 32, 11],\n",
              " [12, 22],\n",
              " [12, 22, 3],\n",
              " [12, 22, 3, 19],\n",
              " [12, 22, 3, 19, 90],\n",
              " [12, 22, 3, 19, 90, 91],\n",
              " [12, 22, 3, 19, 90, 91, 2],\n",
              " [12, 22, 3, 19, 90, 91, 2, 33],\n",
              " [11, 4],\n",
              " [11, 4, 92],\n",
              " [11, 4, 92, 6],\n",
              " [11, 4, 92, 6, 93],\n",
              " [11, 4, 92, 6, 93, 94],\n",
              " [11, 4, 92, 6, 93, 94, 95],\n",
              " [11, 4, 92, 6, 93, 94, 95, 96],\n",
              " [97, 10],\n",
              " [97, 10, 21],\n",
              " [97, 10, 21, 98],\n",
              " [97, 10, 21, 98, 99],\n",
              " [97, 10, 21, 98, 99, 9],\n",
              " [100, 1],\n",
              " [100, 1, 101],\n",
              " [100, 1, 101, 4],\n",
              " [100, 1, 101, 4, 102],\n",
              " [100, 1, 101, 4, 102, 34],\n",
              " [100, 1, 101, 4, 102, 34, 103],\n",
              " [100, 1, 101, 4, 102, 34, 103, 104],\n",
              " [100, 1, 101, 4, 102, 34, 103, 104, 105],\n",
              " [106, 107],\n",
              " [106, 107, 35],\n",
              " [106, 107, 35, 4],\n",
              " [106, 107, 35, 4, 5],\n",
              " [106, 107, 35, 4, 5, 108],\n",
              " [106, 107, 35, 4, 5, 108, 23],\n",
              " [106, 107, 35, 4, 5, 108, 23, 34],\n",
              " [106, 107, 35, 4, 5, 108, 23, 34, 109],\n",
              " [110, 4],\n",
              " [110, 4, 111],\n",
              " [110, 4, 111, 6],\n",
              " [110, 4, 111, 6, 36],\n",
              " [110, 4, 111, 6, 36, 13],\n",
              " [110, 4, 111, 6, 36, 13, 33],\n",
              " [37, 112],\n",
              " [37, 112, 24],\n",
              " [37, 112, 24, 113],\n",
              " [37, 112, 24, 113, 38],\n",
              " [37, 112, 24, 113, 38, 114],\n",
              " [38, 29],\n",
              " [38, 29, 6],\n",
              " [38, 29, 6, 115],\n",
              " [38, 29, 6, 115, 18],\n",
              " [38, 29, 6, 115, 18, 116],\n",
              " [38, 29, 6, 115, 18, 116, 24],\n",
              " [38, 29, 6, 115, 18, 116, 24, 117],\n",
              " [38, 29, 6, 115, 18, 116, 24, 117, 118],\n",
              " [39, 119],\n",
              " [39, 119, 9],\n",
              " [39, 119, 9, 2],\n",
              " [39, 119, 9, 2, 120],\n",
              " [121, 122],\n",
              " [121, 122, 20],\n",
              " [121, 122, 20, 123],\n",
              " [121, 122, 20, 123, 1],\n",
              " [121, 122, 20, 123, 1, 124],\n",
              " [121, 122, 20, 123, 1, 124, 125],\n",
              " [27, 11],\n",
              " [27, 11, 4],\n",
              " [27, 11, 4, 5],\n",
              " [27, 11, 4, 5, 35],\n",
              " [27, 11, 4, 5, 35, 24],\n",
              " [27, 11, 4, 5, 35, 24, 39],\n",
              " [17, 3],\n",
              " [17, 3, 126],\n",
              " [17, 3, 126, 127],\n",
              " [17, 3, 126, 127, 128],\n",
              " [17, 3, 126, 127, 128, 15],\n",
              " [17, 3, 126, 127, 128, 15, 16],\n",
              " [31, 129],\n",
              " [31, 129, 8],\n",
              " [31, 129, 8, 130],\n",
              " [31, 129, 8, 130, 7],\n",
              " [131, 132],\n",
              " [131, 132, 133],\n",
              " [131, 132, 133, 134],\n",
              " [131, 132, 133, 134, 23],\n",
              " [131, 132, 133, 134, 23, 135],\n",
              " [136, 17],\n",
              " [136, 17, 137],\n",
              " [136, 17, 137, 138],\n",
              " [136, 17, 137, 138, 139],\n",
              " [136, 17, 137, 138, 139, 8],\n",
              " [140, 40],\n",
              " [140, 40, 6],\n",
              " [140, 40, 6, 141],\n",
              " [140, 40, 6, 141, 13],\n",
              " [140, 40, 6, 141, 13, 7],\n",
              " [140, 40, 6, 141, 13, 7, 142],\n",
              " [143, 144],\n",
              " [143, 144, 5],\n",
              " [143, 144, 5, 41],\n",
              " [143, 144, 5, 41, 2],\n",
              " [143, 144, 5, 41, 2, 15],\n",
              " [143, 144, 5, 41, 2, 15, 16],\n",
              " [145, 146],\n",
              " [145, 146, 1],\n",
              " [145, 146, 1, 147],\n",
              " [145, 146, 1, 147, 148],\n",
              " [145, 146, 1, 147, 148, 25],\n",
              " [145, 146, 1, 147, 148, 25, 149],\n",
              " [14, 8],\n",
              " [14, 8, 26],\n",
              " [14, 8, 26, 25],\n",
              " [14, 8, 26, 25, 150],\n",
              " [14, 8, 26, 25, 150, 151],\n",
              " [9, 152],\n",
              " [9, 152, 1],\n",
              " [9, 152, 1, 153],\n",
              " [9, 152, 1, 153, 5],\n",
              " [9, 152, 1, 153, 5, 154],\n",
              " [9, 152, 1, 153, 5, 154, 155],\n",
              " [156, 157],\n",
              " [156, 157, 18],\n",
              " [156, 157, 18, 30],\n",
              " [156, 157, 18, 30, 14],\n",
              " [156, 157, 18, 30, 14, 158],\n",
              " [12, 22],\n",
              " [12, 22, 4],\n",
              " [12, 22, 4, 159],\n",
              " [12, 22, 4, 159, 160],\n",
              " [12, 22, 4, 159, 160, 161],\n",
              " [12, 22, 4, 159, 160, 161, 162],\n",
              " [12, 22, 4, 159, 160, 161, 162, 1],\n",
              " [12, 22, 4, 159, 160, 161, 162, 1, 163],\n",
              " [37, 5],\n",
              " [37, 5, 28],\n",
              " [37, 5, 28, 2],\n",
              " [37, 5, 28, 2, 164],\n",
              " [37, 5, 28, 2, 164, 165],\n",
              " [37, 5, 28, 2, 164, 165, 166],\n",
              " [37, 5, 28, 2, 164, 165, 166, 1],\n",
              " [37, 5, 28, 2, 164, 165, 166, 1, 167],\n",
              " [37, 5, 28, 2, 164, 165, 166, 1, 167, 168],\n",
              " [169, 12],\n",
              " [169, 12, 26],\n",
              " [169, 12, 26, 25],\n",
              " [169, 12, 26, 25, 170],\n",
              " [169, 12, 26, 25, 170, 1],\n",
              " [169, 12, 26, 25, 170, 1, 171],\n",
              " [172, 13],\n",
              " [172, 13, 12],\n",
              " [172, 13, 12, 22],\n",
              " [172, 13, 12, 22, 3],\n",
              " [172, 13, 12, 22, 3, 173],\n",
              " [32, 174],\n",
              " [32, 174, 3],\n",
              " [32, 174, 3, 175],\n",
              " [32, 174, 3, 175, 176],\n",
              " [177, 7],\n",
              " [177, 7, 3],\n",
              " [177, 7, 3, 178],\n",
              " [177, 7, 3, 178, 2],\n",
              " [177, 7, 3, 178, 2, 6],\n",
              " [177, 7, 3, 178, 2, 6, 36],\n",
              " [177, 7, 3, 178, 2, 6, 36, 13],\n",
              " [177, 7, 3, 178, 2, 6, 36, 13, 14],\n",
              " [179, 1],\n",
              " [179, 1, 180],\n",
              " [179, 1, 180, 181],\n",
              " [179, 1, 180, 181, 182],\n",
              " [179, 1, 180, 181, 182, 183],\n",
              " [184, 26],\n",
              " [184, 26, 185],\n",
              " [184, 26, 185, 186],\n",
              " [184, 26, 185, 186, 187],\n",
              " [184, 26, 185, 186, 187, 2],\n",
              " [184, 26, 185, 186, 187, 2, 188],\n",
              " [189, 190],\n",
              " [189, 190, 5],\n",
              " [189, 190, 5, 41],\n",
              " [189, 190, 5, 41, 23],\n",
              " [189, 190, 5, 41, 23, 14],\n",
              " [189, 190, 5, 41, 23, 14, 191],\n",
              " [192, 193],\n",
              " [192, 193, 40],\n",
              " [192, 193, 40, 194]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQcQHKKIN1r",
        "outputId": "b65ba338-7a4f-48f1-a663-ebb169c6da31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UormTF7T3_Zs",
        "outputId": "8af7085a-ba6b-437f-fb72-7473b9d07601"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import pad\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences= pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "fLVJV2coI-v4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWAjtOkmKFrO",
        "outputId": "8d30c56b-fc9d-42ad-8211-7cd959f74e00"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  15,  16],\n",
              "       [  0,   0,   0, ...,  15,  16,   3],\n",
              "       [  0,   0,   0, ...,  16,   3,  42],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0, 192, 193],\n",
              "       [  0,   0,   0, ..., 192, 193,  40],\n",
              "       [  0,   0,   0, ..., 193,  40, 194]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "O4otZi4CKai7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "d8cv6ksKKu8S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA4AmVUGK784",
        "outputId": "0281a6dd-8db1-4b41-b60a-8d2b5fe13e27"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz9NGUny1QOr",
        "outputId": "f97c8b04-a86f-4da6-d29d-63e6151b2f5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=197)"
      ],
      "metadata": {
        "id": "t8emXwl71UGl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGjMCcou2aS5",
        "outputId": "d92f6402-5d7b-4d84-c0bf-999fd02ec165"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 197)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "uoNtipPI2SX2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXJmcEbe4qnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-Ui5uhe4q_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(197,100,input_length=10))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(197,activation='softmax'))"
      ],
      "metadata": {
        "id": "vcHI7I5X4lO3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Rmalv_Zv4p_F"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 9))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "TANBd1sB5Oay",
        "outputId": "dda5fc30-0787-48dd-b74a-eb75241837a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │        \u001b[38;5;34m19,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m)            │        \u001b[38;5;34m29,747\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,747</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,047\u001b[0m (781.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,047</span> (781.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,047\u001b[0m (781.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,047</span> (781.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9JEbvCa6xmj",
        "outputId": "134b6cdf-ce31-4860-d12d-95dbe71d6349"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0099 - loss: 5.2825\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0363 - loss: 5.2456\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0288 - loss: 5.1139\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0405 - loss: 4.9248\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0523 - loss: 4.8978\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0381 - loss: 4.8718\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0465 - loss: 4.8179\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0587 - loss: 4.8324\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0590 - loss: 4.8320\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0650 - loss: 4.6706\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0666 - loss: 4.6882\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0963 - loss: 4.5434\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0654 - loss: 4.4905\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0725 - loss: 4.4069\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0662 - loss: 4.2507\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1145 - loss: 4.1266\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1434 - loss: 4.0228\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1771 - loss: 3.9720\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2081 - loss: 3.7167\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1626 - loss: 3.7769\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2213 - loss: 3.6236\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2176 - loss: 3.4392\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2615 - loss: 3.3080\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3291 - loss: 3.1511\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3184 - loss: 3.1305\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3612 - loss: 2.9089\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4132 - loss: 2.8070\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4315 - loss: 2.6859\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4628 - loss: 2.5638\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4983 - loss: 2.4535\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5353 - loss: 2.3817\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5649 - loss: 2.2840\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6052 - loss: 2.1366\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6131 - loss: 2.0989\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6256 - loss: 1.9406\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6701 - loss: 1.8550\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7032 - loss: 1.7181\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6700 - loss: 1.7483\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6883 - loss: 1.6529\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7180 - loss: 1.5618\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7418 - loss: 1.4838\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7517 - loss: 1.4275\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7552 - loss: 1.3983\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7666 - loss: 1.3413\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8009 - loss: 1.2483\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8236 - loss: 1.2194\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8224 - loss: 1.1729\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8154 - loss: 1.1403\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8771 - loss: 0.9861\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8600 - loss: 1.0071\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8775 - loss: 0.9225\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9142 - loss: 0.8193\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8832 - loss: 0.8798\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9012 - loss: 0.9177\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8945 - loss: 0.8174\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8991 - loss: 0.7710\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9233 - loss: 0.7477\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9334 - loss: 0.7104\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9563 - loss: 0.6569\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9542 - loss: 0.6459\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9646 - loss: 0.5920\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9715 - loss: 0.5765\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9658 - loss: 0.5295\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9463 - loss: 0.5729\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9712 - loss: 0.5235\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9658 - loss: 0.4971\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9871 - loss: 0.4831\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9749 - loss: 0.4521\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9883 - loss: 0.4332\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9844 - loss: 0.4177\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9955 - loss: 0.3976\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9823 - loss: 0.3992\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9837 - loss: 0.3470\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9815 - loss: 0.3481\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9858 - loss: 0.3499\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9820 - loss: 0.3157\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9896 - loss: 0.3316\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9910 - loss: 0.2816\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.2899\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9863 - loss: 0.2669\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9897 - loss: 0.2551\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9901 - loss: 0.2590\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9875 - loss: 0.2247\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9946 - loss: 0.2277\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9903 - loss: 0.2217\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9829 - loss: 0.2281\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9873 - loss: 0.2182\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.2024\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9832 - loss: 0.1899\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9858 - loss: 0.2065\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9887 - loss: 0.1845\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9879 - loss: 0.1787\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9855 - loss: 0.1749\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9899 - loss: 0.1724\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9849 - loss: 0.1702\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9923 - loss: 0.1470\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9864 - loss: 0.1495\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9899 - loss: 0.1497\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9841 - loss: 0.1494\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9952 - loss: 0.1336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2dbc1dddc0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bIl9mPEw7Gvo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OE45Ge2Y8pbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "text = \"experimentation\"\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    padded_token_text = pad_sequences(\n",
        "        [token_text],\n",
        "        maxlen=9,\n",
        "        padding='pre'\n",
        "    )\n",
        "\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "    from word,pos in tokenizer.word_index.items():\n",
        "        if pos == np.argmax(model.predict(padded_token_text)):\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE31s7lC7HRo",
        "outputId": "0483cc86-8856-494a-a3ed-5f4abbf20dfd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "experimentation enhances\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "experimentation enhances understanding\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "experimentation enhances understanding understanding\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "experimentation enhances understanding understanding in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "experimentation enhances understanding understanding in of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "experimentation enhances understanding understanding in of nlp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "experimentation enhances understanding understanding in of nlp nlp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "experimentation enhances understanding understanding in of nlp nlp experience\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "experimentation enhances understanding understanding in of nlp nlp experience creation\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "experimentation enhances understanding understanding in of nlp nlp experience creation context\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuWT65hV-5rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "HWQkleCJ9Sfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "text = \"natural\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    padded_token_text = pad_sequences(\n",
        "        [token_text],\n",
        "        maxlen=9,\n",
        "        padding='pre'\n",
        "    )\n",
        "\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == pos:\n",
        "        text += \" \" + word\n",
        "        print(text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fesIiwra-8BX",
        "outputId": "a3f91da7-b6b9-425f-f264-bbd4c750aa6c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "natural language\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "natural language processing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "natural language processing helps\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "natural language processing helps computers\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "natural language processing helps computers understand\n"
          ]
        }
      ]
    }
  ]
}