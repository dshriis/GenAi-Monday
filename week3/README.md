# ğŸ§  Variational Autoencoder (VAE) â€“ Image Generation Lab

## ğŸ“Œ Objective

Implement and train a Variational Autoencoder (VAE) that:
- Learns latent representations of image data
- Reconstructs input images with high fidelity
- Generates new, unseen images using the MNIST handwritten digits dataset
- Visualizes the learned latent space

---

## ğŸ¤– What is a Variational Autoencoder (VAE)?

A Variational Autoencoder is a **generative deep learning model** that learns a **probability distribution** over data instead of fixed encodings. Unlike standard autoencoders, VAEs enable:
- **Smooth latent representations** â€“ interpolation between data points
- **Diverse generation** â€“ sampling from learned probability distribution
- **Interpretable latent space** â€“ meaningful dimensions (especially with 2D latent space)

---

## ğŸ”¹ VAE Architecture

### **Encoder**
- Compresses input images (28Ã—28) into a probabilistic latent representation
- Outputs mean vector (Î¼) and log-variance (log ÏƒÂ²)
- Creates a continuous latent space

### **Reparameterization Trick**
Enables backpropagation through randomness by reformulating sampling:

$$z = \mu + \sigma \cdot \epsilon$$

where $\epsilon \sim \mathcal{N}(0, I)$

### **Decoder**
- Reconstructs images from latent vectors
- Enables generation of new images from randomly sampled latent points
- Outputs sigmoid activation for pixel values in [0,1]

---

## ğŸ§© Implementation Configuration

| Parameter | Value |
|-----------|-------|
| **Dataset** | MNIST (handwritten digits) |
| **Image Size** | 28Ã—28 pixels (grayscale) |
| **Batch Size** | 128 |
| **Epochs** | 20 |
| **Latent Dimension** | 2 |
| **Optimizer** | Adam (lr=1e-3) |
| **Loss Function** | Reconstruction Loss (BCE) + KL Divergence |
| **Train/Test Split** | 60,000 / 10,000 |

---

## ğŸ“Š Loss Function Components

**Total Loss = Reconstruction Loss + Î² Ã— KL Divergence**

- **Reconstruction Loss (BCE):** Measures how well decoded images match originals
- **KL Divergence:** Regularizes latent space to follow standard normal distribution
- **Î² (Beta):** Weight balancing reconstruction vs. regularization

---

## ğŸ–¼ï¸ Expected Results

âœ… **Reconstruction Quality**
- Reconstructed images closely resemble original digits
- Minimal pixel-level differences for test samples

âœ… **Generation Quality**
- Generated images are novel and diverse
- Smooth transitions between digit classes in latent space

âœ… **Training Dynamics**
- Overall loss decreases steadily (indicates stable learning)
- Reconstruction and KL loss balance over epochs

---

## ğŸš€ Key Features to Explore

1. **Latent Space Visualization** â€“ 2D scatter plot of encoded test samples colored by digit class
2. **Image Interpolation** â€“ Generate smooth transitions between two digits
3. **Random Generation** â€“ Sample from standard normal and decode to create new digits
4. **Reconstruction Analysis** â€“ Compare original vs. reconstructed images

---

## âœ… Conclusion

The Variational Autoencoder successfully:
- Learns a **structured latent space** with meaningful dimensions
- Enables **effective image reconstruction** across training and test sets
- Supports **diverse image generation** from sampled latent vectors
- Demonstrates the power of **probabilistic generative modeling**

we implemented a Variational Autoencoder (VAE) using PyTorch and trained it on the MNIST handwritten digits dataset.
We built an encoder that maps input images to a latent probability distribution defined by mean and log-variance, applied the reparameterization trick to sample latent vectors, and used a decoder to reconstruct images.
The model was trained using a combined loss function consisting of Binary Cross-Entropy reconstruction loss and KL-divergence loss.
After training, we evaluated the model by reconstructing test images, generating new digit samples from random latent vectors, and visualizing the training loss curve to analyze learning behavior.