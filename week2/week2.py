# -*- coding: utf-8 -*-
"""week2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QYdzA9HD4I63OYD3NKp5DomQNMY68egO
"""

import torch

print("CUDA Available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU:", torch.cuda.get_device_name(0))

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision.utils import save_image
import os

# ===== CONFIG =====
dataset_choice = "fashion"   # "mnist" or "fashion"
epochs = 30
batch_size = 128
noise_dim = 100
lr = 0.0002
save_interval = 5
# =================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

os.makedirs("generated_samples", exist_ok=True)
os.makedirs("final_generated_images", exist_ok=True)

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

if dataset_choice == "fashion":
    dataset = datasets.FashionMNIST(
        "./data", train=True, download=True, transform=transform
    )
else:
    dataset = datasets.MNIST(
        "./data", train=True, download=True, transform=transform
    )

dataloader = DataLoader(
    dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=2,
    pin_memory=True
)

print("Total training images:", len(dataset))

class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(noise_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, 784),
            nn.Tanh()
        )

    def forward(self, z):
        return self.net(z).view(-1, 1, 28, 28)


class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Flatten(),
            nn.Linear(784, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)


G = Generator().to(device)
D = Discriminator().to(device)

criterion = nn.BCELoss()

optG = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))
optD = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))

for epoch in range(1, epochs + 1):
    d_loss, g_loss = 0, 0
    correct, total = 0, 0

    for real, _ in dataloader:
        real = real.to(device)
        b = real.size(0)

        real_labels = torch.ones(b, 1, device=device)
        fake_labels = torch.zeros(b, 1, device=device)

        # ---- Train Discriminator ----
        noise = torch.randn(b, noise_dim, device=device)
        fake = G(noise)

        D_real = D(real)
        D_fake = D(fake.detach())

        lossD = criterion(D_real, real_labels) + criterion(D_fake, fake_labels)

        optD.zero_grad()
        lossD.backward()
        optD.step()

        correct += (D_real > 0.5).sum().item()
        correct += (D_fake < 0.5).sum().item()
        total += 2 * b

        # ---- Train Generator ----
        D_fake2 = D(fake)
        lossG = criterion(D_fake2, real_labels)

        optG.zero_grad()
        lossG.backward()
        optG.step()

        d_loss += lossD.item()
        g_loss += lossG.item()

    print(
        f"Epoch {epoch}/{epochs} | "
        f"D_loss {d_loss/len(dataloader):.3f} | "
        f"G_loss {g_loss/len(dataloader):.3f} | "
        f"D_acc {(100*correct/total):.2f}%"
    )

    if epoch % save_interval == 0:
        with torch.no_grad():
            z = torch.randn(25, noise_dim, device=device)
            samples = G(z)
            save_image(
                samples,
                f"generated_samples/epoch_{epoch}.png",
                nrow=5,
                normalize=True
            )

with torch.no_grad():
    z = torch.randn(100, noise_dim, device=device)
    final_images = G(z)

for i, img in enumerate(final_images):
    save_image(
        img,
        f"final_generated_images/img_{i:03d}.png",
        normalize=True
    )

print("Saved 100 final images")

from google.colab import files

files.download("generated_samples")
files.download("final_generated_images")